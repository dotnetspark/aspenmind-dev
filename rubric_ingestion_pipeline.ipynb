{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6149af44",
   "metadata": {},
   "source": [
    "# JD‚ÄëNext Rubric Ingestion Pipeline\n",
    "\n",
    "This notebook ingests rubric rules, item‚Äëwriting principles, examples, and construct definitions into the existing Azure AI Search index.\n",
    "\n",
    "It uses the same schema as `exam_ingestion_pipeline.ipynb`, but only populates:\n",
    "\n",
    "- `id`\n",
    "- `domain = \"rubric\"`\n",
    "- `topic`\n",
    "- `full_text`\n",
    "- `content_vector`\n",
    "\n",
    "All other fields remain `None`.\n",
    "\n",
    "This keeps rubric ingestion clean, modular, and fully compatible with the unified index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b94c8c",
   "metadata": {},
   "source": [
    "### üîê Step 2: Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b977957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_KEY = os.getenv(\"AZURE_SEARCH_KEY\")\n",
    "AZURE_RUBRIC_INDEX = os.getenv(\"AZURE_RUBRIC_INDEX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98811505",
   "metadata": {},
   "source": [
    "### üß± Step 4: Create the Azure AI Search index (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ec3671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created index: jdn-rubric-index\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    credential=AzureKeyCredential(AZURE_SEARCH_KEY)\n",
    ")\n",
    "\n",
    "embedding_dimensions = 1536\n",
    "\n",
    "index_schema = SearchIndex(\n",
    "    name=AZURE_RUBRIC_INDEX,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=SearchFieldDataType.String, key=True, searchable=False),\n",
    "        SearchField(name=\"category\", type=SearchFieldDataType.String, searchable=True, filterable=True),\n",
    "        SearchField(name=\"subsection\", type=SearchFieldDataType.String, searchable=True, filterable=True),\n",
    "        SearchField(name=\"type\", type=SearchFieldDataType.String, searchable=True, filterable=True),\n",
    "        SearchField(name=\"content\", type=SearchFieldDataType.String, searchable=True), \n",
    "        SearchField(name=\"order\", type=SearchFieldDataType.Int32, filterable=True, sortable=True), \n",
    "        SearchField(name=\"full_text\", type=SearchFieldDataType.String, searchable=True),\n",
    "\n",
    "        SearchField(\n",
    "            name=\"content_vector\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            searchable=True,\n",
    "            vector_search_dimensions=embedding_dimensions,\n",
    "            vector_search_profile_name=\"rubricHnswProfile\"\n",
    "        )\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"rubricHnsw\",\n",
    "                kind=\"hnsw\"\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"rubricHnswProfile\",\n",
    "                algorithm_configuration_name=\"rubricHnsw\"\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "if AZURE_RUBRIC_INDEX not in index_client.list_index_names():\n",
    "    index_client.create_index(index_schema)\n",
    "    print(f\"‚úÖ Created index: {AZURE_RUBRIC_INDEX}\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è Index '{AZURE_RUBRIC_INDEX}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32bc43",
   "metadata": {},
   "source": [
    "### üìÑ Load your CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c046811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 166 rubric chunks.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'order': 1,\n",
       "  'category': 'CONSTRUCT',\n",
       "  'subsection': 'Construct',\n",
       "  'type': 'HEADER',\n",
       "  'content': 'Construct',\n",
       "  'section': 'Construct',\n",
       "  'source': 'Construct.txt'},\n",
       " {'order': 2,\n",
       "  'category': 'CONSTRUCT',\n",
       "  'subsection': 'Construct',\n",
       "  'type': 'DEFINITION',\n",
       "  'content': 'A construct is the Knowledge, Skills, and Abilities (KSAs) we intend to measure in an assessment.',\n",
       "  'section': 'Construct',\n",
       "  'source': 'Construct.txt'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "RUBRIC_JSONL_PATH = \"./item-writing/JD-Next Item-Writing rubric.jsonl\"\n",
    "\n",
    "rubric_chunks = []\n",
    "\n",
    "with open(RUBRIC_JSONL_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            rubric_chunks.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(rubric_chunks)} rubric chunks.\")\n",
    "rubric_chunks[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c2d0f4",
   "metadata": {},
   "source": [
    "## üß† Normalize chunks into a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15034469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized 166 documents.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'ee7471f5-eaa6-4ce7-8b7a-cb45c71dfc41',\n",
       " 'category': 'CONSTRUCT',\n",
       " 'subsection': 'Construct',\n",
       " 'type': 'HEADER',\n",
       " 'content': 'Construct',\n",
       " 'order': 1,\n",
       " 'full_text': 'Construct',\n",
       " 'content_vector': None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "def normalize_rubric_chunk(chunk):\n",
    "    \"\"\"\n",
    "    Convert a JSONL rubric chunk into an Azure Search document.\n",
    "    \"\"\"\n",
    "    doc = {\n",
    "        \"id\": str(uuid.uuid4()),  # unique ID\n",
    "        \"category\": chunk.get(\"category\", \"\"),\n",
    "        \"subsection\": chunk.get(\"subsection\", \"\"),\n",
    "        \"type\": chunk.get(\"type\", \"\"),\n",
    "        \"content\": chunk.get(\"content\", \"\"),\n",
    "        \"order\": chunk.get(\"order\", 0),\n",
    "        \"full_text\": chunk.get(\"content\", \"\"),  # can expand later\n",
    "        \"content_vector\": None  # filled in next cell\n",
    "    }\n",
    "    return doc\n",
    "\n",
    "rubric_docs = [normalize_rubric_chunk(c) for c in rubric_chunks]\n",
    "\n",
    "print(f\"Normalized {len(rubric_docs)} documents.\")\n",
    "rubric_docs[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ae7aed",
   "metadata": {},
   "source": [
    "### üß¨ Generate embeddings for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9b73a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 0 embedding (first 4 dims): [0.01560912560671568, 0.007811433169990778, -0.0362197682261467, 0.027563298121094704]\n",
      "Doc 1 embedding (first 4 dims): [0.033380910754203796, 0.011718349531292915, 0.012452865950763226, 0.006616291124373674]\n",
      "Doc 2 embedding (first 4 dims): [0.036775168031454086, 0.019434520974755287, 0.004527701530605555, 0.017834030091762543]\n",
      "... (embeddings for remaining documents not shown)\n",
      "Embedded 166 documents.\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "def embed(text):\n",
    "    response = client.embeddings.create(\n",
    "        model=AZURE_OPENAI_EMBEDDING_MODEL,\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "for doc in rubric_docs:\n",
    "    doc[\"content_vector\"] = embed(doc[\"full_text\"])\n",
    "\n",
    "for i, doc in enumerate(rubric_docs[:3]):\n",
    "    print(f\"Doc {i} embedding (first 4 dims): {doc['content_vector'][:4]}\")\n",
    "print(\"... (embeddings for remaining documents not shown)\")\n",
    "\n",
    "print(f\"Embedded {len(rubric_docs)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d2b59",
   "metadata": {},
   "source": [
    "### üöÄ Upload documents in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "176bb736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Uploaded batch 1: 100 documents\n",
      "‚úÖ Uploaded batch 2: 66 documents\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    index_name=AZURE_RUBRIC_INDEX,\n",
    "    credential=AzureKeyCredential(AZURE_SEARCH_KEY)\n",
    ")\n",
    "\n",
    "batch_size = 100\n",
    "for i in range(0, len(rubric_docs), batch_size):\n",
    "    batch = rubric_docs[i:i+batch_size]\n",
    "    result = search_client.upload_documents(documents=batch)\n",
    "    print(f\"‚úÖ Uploaded batch {i//batch_size + 1}: {len(batch)} documents\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
